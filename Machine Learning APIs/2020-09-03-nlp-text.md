---
layout: post
title: Machine Learning APIs - 03
date: 2020-09-03
excerpt: "Classify Text into Categories with the Natural Language API"
tags: [qwiklab, ML, google]
comments: true
---

本教學，環境會設置好 `Cloud Natural Language API`、`VM Instance`。

## Classify a news article

使用 ` Natural Language API` 的 `classifyText` 方法，可以透過單個 `API` 調用將文本數據分類為類別，此方法返回適用於文本文檔的內容類別的列表。這些類別的範圍很廣，從 `/Computers&Electronics` 等廣泛類別到 `/Computers&Electronics/Programming/Java`（程式語言）等高度特定的類別。可以在[此處](https://cloud.google.com/natural-language/docs/categories)找到 700 多種可能類別的完整列表。

實驗將從對單個文章進行分類開始，然後我們將了解如何使用此方法來理解大型新聞語料庫。


建立 `request.json`

```json
{
  "document":{
    "type":"PLAIN_TEXT",
    "content":"A Smoky Lobster Salad With a Tapa Twist. This spin on the Spanish pulpo a la gallega skips the octopus, but keeps the sea salt, olive oil, pimentón and boiled potatoes."
  }
}
```
使用以下命令將此文本發送到 `Natural Language API` 的 `classifyText` 方法：

```shell
curl "https://language.googleapis.com/v1/documents:classifyText?key=${API_KEY}" \
  -s -X POST -H "Content-Type: application/json" --data-binary @request.json
```
回應

```shell
{ categories:
  [
    {
      name: '/Food & Drink/Cooking & Recipes',
       confidence: 0.85
    },
    {
       name: '/Food & Drink/Food/Meat & Seafood',
       confidence: 0.63
     }
  ]
}
```

創建了 `Speech API ` 請求，然後將其稱為 `Speech API `。運行以下命令將回應保存在 `result.json` 檔案

```shell
curl "https://language.googleapis.com/v1/documents:classifyText?key=${API_KEY}" \
  -s -X POST -H "Content-Type: application/json" --data-binary @request.json > result.json
```

`API` 針對此文本返回了 2 個類別：
- `/Food & Drink/Cooking & Recipes`
- `/Food & Drink/Food/Meat & Seafood`


文字並未明確提及這是一種食譜，甚至沒有提及海鮮，但 `API` 可以對其進行分類。對單個文章進行分類很酷，但是要真正了解此功能的強大功能，讓我們對大量文本數據進行分類。


## Classifying a large text dataset

使用 BBC [數據集](http://mlg.ucd.ie/datasets/bbc.html)，這些文章的子集位於公有 `Cloud Storage` 存儲桶中，每筆文章都位於一個`.txt`檔案中。

要檢查數據並將其發送到 `Natural Language API`，編寫一個 `Python` 從 `Cloud Storage` 中讀取每個文本檔案，將其發送到 `classifyText` 端點，並將結果存儲在 `BigQuery` 表中。`BigQuery` 是 `Google Cloud` 的大數據倉儲工具，可以輕鬆儲存和分析大數據。

運行以下

```shell
gsutil cat gs://spls/gsp063/bbc_dataset/entertainment/001.txt # 查看一篇文章
```

## Creating a BigQuery table for our categorized text data

在將文本發送到 `Natural Language API` 前，需要一個位置來儲存每篇文章的文本和類別。

在 `Navigate` 選擇 `BigQuery`

![](https://i.imgur.com/5ujdFlP.png)


然後點擊專案名稱，然後點擊 `Create dataset` 數據集：

![](https://i.imgur.com/IuJ4upG.png)
![](https://i.imgur.com/rEMxl7D.png)

將數據集命名為 `new​​s_classification_dataset`。然後點擊創 `Create dataset`。再點擊數據集的名稱，然後選擇 `Create Table`。對新表使用以下設置：

- Create From: empty table
- 表格命名為 `article_data`
- 點擊 `Add Field`，然後添加以下 3 個字段：`article_text`、`category` 和 `confidence`

![](https://i.imgur.com/L84TAmh.png)
![](https://i.imgur.com/D1NGZJj.png)
![](https://i.imgur.com/5SVZ7yR.png)


最後點擊 `Create Table`

## Classifying news data and storing the result in BigQuery

在編寫程式以將新聞數據發送到 `Natural Language API` 之前，需要創建一個 `service account`。這將用於透過 `Python` 向 `Natural Language API` 和 `BigQuery` 進行身份驗證。

```shell
export PROJECT=<your_project_name>
```

```shell
gcloud iam service-accounts create my-account --display-name my-account
gcloud projects add-iam-policy-binding $PROJECT --member=serviceAccount:my-account@$PROJECT.iam.gserviceaccount.com --role=roles/bigquery.admin
gcloud iam service-accounts keys create key.json --iam-account=my-account@$PROJECT.iam.gserviceaccount.com
export GOOGLE_APPLICATION_CREDENTIALS=key.json
```

`classify-text.py`
```python
from google.cloud import storage, language, bigquery

# Set up our GCS, NL, and BigQuery clients
storage_client = storage.Client()
nl_client = language.LanguageServiceClient()
# TODO: replace YOUR_PROJECT with your project name below
bq_client = bigquery.Client(project='YOUR_PROJECT') # 改成 project ID

dataset_ref = bq_client.dataset('news_classification_dataset')
dataset = bigquery.Dataset(dataset_ref)
table_ref = dataset.table('article_data')
table = bq_client.get_table(table_ref)

# Send article text to the NL API's classifyText method
def classify_text(article):
        response = nl_client.classify_text(
                document=language.types.Document(
                        content=article,
                        type=language.enums.Document.Type.PLAIN_TEXT
                )
        )
        return response


rows_for_bq = []
files = storage_client.bucket('qwiklabs-test-bucket-gsp063').list_blobs()
print("Got article files from GCS, sending them to the NL API (this will take ~2 minutes)...")

# Send files to the NL API and save the result to send to BigQuery
for file in files:
        if file.name.endswith('txt'):
                article_text = file.download_as_string()
                nl_response = classify_text(article_text)
                if len(nl_response.categories) > 0:
                        rows_for_bq.append((str(article_text), nl_response.categories[0].name, nl_response.categories[0].confidence))

print("Writing NL API article data to BigQuery...")
# Write article text + category data to BQ
errors = bq_client.insert_rows(table, rows_for_bq)
assert errors == []
```

開始對文章進行分類並將其導入到 `BigQuery` 中，運行上述所撰寫的 `python`

```shell
python3 classify-text.py
```

使用 `google-cloud` [Python客戶端函式庫](https://googlecloudplatform.github.io/google-cloud-python/)來訪問 `Cloud Storage`、`Natural Language API` 和 `BigQuery`。首先，為每個服務創建一個客戶端。然後創建對 `BigQuery` 表的引用。`files` 是對公有儲存桶中每個 BBC 數據集檔案的引用。我們遍歷這些檔案，將文章下載為字串，然後將每個文章發送到 `classify_text` 函式中的 `Natural Language API`。對於所有使用 `Natural Language API` 返回類別的文章，文章及其類別數據都保存到 `rows_for_bq` 列表中。完成每篇文章的分類後，將使用 `insert_rows()` 將數據插入到`BigQuery` 中。

>`Natural Language API` 可以為一個文檔返回多個類別，但對於本實驗，僅儲存返回的第一個類別使事情變得簡單。

當 python 運行完後，在 `BigQuery` 中，導航(navigate)到 `BigQuery` 標籤中的 `article_data` 表，然後單擊查詢表：

圖


在Unsaved query (未保存的查詢)框中編輯結果，在 `SELECT` 和 `FROM` 之間添加一個星號：

```shell
SELECT * FROM `YOUR_PROJECT.news_classification_dataset.article_data`
```

![](https://i.imgur.com/25E3PG1.png)

查詢完成後，將看到數據，滾動到右側以查看類別列。`category` 列的名稱是為該文章返回的 `Natural Language API` 的第一個類別，`confidence` 是介於 0 和 1 之間的值，指示 `API` 對文章正確分類的信心程度。


## Analyzing categorized news data in BigQuery

查看數據集中最常見的類別。在 `BigQuery` 控制台中，單擊 `Compose New Query`。執行以下

```shell
SELECT
  category,
  COUNT(*) c
FROM
  `YOUR_PROJECT.news_classification_dataset.article_data`
GROUP BY
  category
ORDER BY
  c DESC
```

結果

![](https://i.imgur.com/nKeFE24.png)

如果想找到返回的文章屬於較模糊的類別，例如 `/Arts & Entertainment/Music & Audio/Classical Music`，則可以編寫以下查詢：

```shell
SELECT * FROM `YOUR_PROJECT.news_classification_dataset.article_data`
WHERE category = "/Arts & Entertainment/Music & Audio/Classical Music"
```
![](https://i.imgur.com/El6miDU.png)

或者，只能獲得 `Natural Language API` 返回的置信度得分大於 90% 的文章：

```shell
SELECT
  article_text,
  category
FROM `YOUR_PROJECT.news_classification_dataset.article_data`
WHERE cast(confidence as float64) > 0.9
```

![](https://i.imgur.com/9V1BSWM.png)

要對數據執行更多查詢，可瀏覽 [BigQuery document](https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators)，`BigQuery` 還整合了許多可視化工具。要創建分類新聞數據的可視化效果，請查看用於 `BigQuery` 的 [Data Studio](https://cloud.google.com/bigquery/docs/visualize-data-studio) 快速入門。